import os
import csv
import math
import pandas as pd
import torch
import torchvision
from PIL import Image
from torch.utils.data import DataLoader
from torchvision.transforms import functional as F
from tqdm import tqdm
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score
from confusion_matrix import compute_confusion_matrix

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª CUDA
CUDA_LAUNCH_BLOCKING = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("ğŸš€ Device:", device)

# Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
root_dir = r"E:\FASTRCNN\FASTRCNN\dataset2\balanced_dataset"
combine_result_dir = os.path.join(root_dir, "heckpoints_AZ5_TRY1", "COMBINE_RESULT")

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
os.makedirs(combine_result_dir, exist_ok=True)

# ---------------------------- 1ï¸âƒ£ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª ----------------------------
class trDataset(torch.utils.data.Dataset):
    def __init__(self, root, phase):
        self.root = root
        self.phase = phase
        self.targets = pd.read_csv(os.path.join(root, f'{phase}_labels.csv'))
        self.imgs = self.targets['filename'].astype(str)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root, r'\FASTRCNN\FASTRCNN\dataset2\balanced_dataset', 'images', self.imgs[idx])
        img = Image.open(img_path).convert('RGB')
        img = F.to_tensor(img)

        filename = self.imgs[idx]
        return img, filename

    def __len__(self):
        return len(self.imgs)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡
test_dataset = trDataset(root_dir, 'test')
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# ---------------------------- 2ï¸âƒ£ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ----------------------------
output_folder = os.path.join(combine_result_dir, "predicted_boxes")
os.makedirs(output_folder, exist_ok=True)
print(f"ğŸ“‚ Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„: {output_folder}")

model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="DEFAULT")
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(1024, 5)
checkpoint = torch.load(os.path.join(root_dir, r"E:\FASTRCNN\FASTRCNN\dataset2\balanced_dataset\checkpoints_AZ5_TRY1", "fold3_best.pth"))

# First inspect what keys are available
print("Checkpoint keys:", checkpoint.keys())

# Then try the appropriate loading method
if 'model_state_dict' in checkpoint:
    model.load_state_dict(checkpoint['model_state_dict'])
elif 'state_dict' in checkpoint:
    model.load_state_dict(checkpoint['state_dict'])
else:
    # If checkpoint is the model itself
    model.load_state_dict(checkpoint)

model.to(device)

model.eval()
print("ğŸ” Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ø§ Ù…Ø¯Ù„...")

with torch.no_grad():
    for images, filenames in tqdm(test_loader, desc="ğŸ“¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±"):
        images = [image.to(device) for image in images]
        out = model(images)

        for i, (filename, prediction) in enumerate(zip(filenames, out)):
            # Ø¯Ø±ÛŒØ§ÙØª Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ù‡â€ŒØ¯Ø±Ø³ØªÛŒ
            if isinstance(filename, list) or isinstance(filename, tuple):
                filename_str = filename[0]
            else:
                filename_str = str(filename)

            filename_str = os.path.basename(str(filename_str))
            filename_str = os.path.splitext(filename_str)[0]

            # Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ CSV
            output_csv_file = os.path.join(output_folder, f"{filename_str}.csv")

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„
            boxes = prediction['boxes'].cpu().numpy()
            labels = prediction['labels'].cpu().numpy()
            scores = prediction['scores'].cpu().numpy()

            # Ø³Ø§Ø®ØªÙ† Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            data = [
                [filename_str, label, int(xmin), int(ymin), int(xmax), int(ymax), float(score)]
                for box, label, score in zip(boxes, labels, scores)
                for xmin, ymin, xmax, ymax in [box]
            ]

            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            df = pd.DataFrame(data, columns=['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax', 'score'])

            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ `filename` Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† `str` Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯
            df['filename'] = df['filename'].astype(str)

            # Ø°Ø®ÛŒØ±Ù‡ CSV Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù†Ø§Ù… ÙØ§ÛŒÙ„
            df.to_csv(output_csv_file, index=False)

print("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

# ---------------------------- 3ï¸âƒ£ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ IoU Ø¨Ø§ GT ----------------------------
filtered_dots_folder = os.path.join(combine_result_dir, "filtered_predicted_dots")
os.makedirs(filtered_dots_folder, exist_ok=True)

# ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ IoU Ø¨ÛŒÙ† Ø¯Ùˆ Ø¨Ø§Ú©Ø³
def calculate_iou(box1, box2):
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø´ØªØ±Ø§Ú©
    inter_x_min = max(x1_min, x2_min)
    inter_y_min = max(y1_min, y2_min)
    inter_x_max = min(x1_max, x2_max)
    inter_y_max = min(y1_max, y2_max)

    # Ù…Ø³Ø§Ø­Øª Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø´ØªØ±Ø§Ú©
    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)

    # Ù…Ø³Ø§Ø­Øª Ù‡Ø± Ø¨Ø§Ú©Ø³
    area1 = (x1_max - x1_min) * (y1_max - y1_min)
    area2 = (x2_max - x2_min) * (y2_max - y2_min)

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ IoU
    iou = inter_area / (area1 + area2 - inter_area + 1e-6)  # +1e-6 Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ±
    return iou

# ØªØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
def process_files(boxes_file, gt_df, output_file):
    boxes_df = pd.read_csv(boxes_file)
    output_rows = []

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§ÛŒ GT Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÛŒÙ† ØªØµÙˆÛŒØ± (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù… ÙØ§ÛŒÙ„)
    filename = os.path.splitext(os.path.basename(boxes_file))[0] + '.tif'  # ØªØ·Ø§Ø¨Ù‚ Ù†Ø§Ù… ÙØ§ÛŒÙ„
    gt_boxes = gt_df[gt_df['filename'] == filename]

    for _, gt_row in gt_boxes.iterrows():
        gt_box = [gt_row['xmin'], gt_row['ymin'], gt_row['xmax'], gt_row['ymax']]

        best_box = None
        best_iou = -1
        best_score = -1

        for _, box_row in boxes_df.iterrows():
            pred_box = [box_row['xmin'], box_row['ymin'], box_row['xmax'], box_row['ymax']]
            score = box_row['score']
            iou = calculate_iou(gt_box, pred_box)

            if iou > 0.5 and (iou > best_iou or (iou == best_iou and score > best_score)):
                best_box = box_row
                best_iou = iou
                best_score = score

        if best_box is not None:
            output_rows.append(best_box.to_dict())

    output_df = pd.DataFrame(output_rows)
    output_df.to_csv(output_file, index=False)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ GT (test_labels.csv)
test_labels_path = os.path.join(root_dir, "test_labels.csv")
gt_df = pd.read_csv(test_labels_path)

# Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡
for pred_filename in tqdm(os.listdir(output_folder), desc="ğŸ” ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ IoU Ø¨Ø§ GT"):
    if pred_filename.endswith(".csv"):
        boxes_file = os.path.join(output_folder, pred_filename)
        output_file = os.path.join(filtered_dots_folder, pred_filename)
        process_files(boxes_file, gt_df, output_file)

print("âœ… ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ IoU Ø¨Ø§ GT Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

# ---------------------------- 4ï¸âƒ£ ØªØ¬Ù…ÛŒØ¹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ----------------------------
merged_file_path = os.path.join(combine_result_dir, "merged_predictions.csv")

merged_data = []
for csv_file in tqdm(os.listdir(filtered_dots_folder), desc="ğŸ”„ ØªØ¬Ù…ÛŒØ¹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§"):
    if csv_file.endswith(".csv"):
        file_path = os.path.join(filtered_dots_folder, csv_file)
        df = pd.read_csv(file_path)

        # Ø§ØµÙ„Ø§Ø­ Ù†Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: Ø­Ø°Ù ".0" Ùˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù¾Ø³ÙˆÙ†Ø¯ ".tif"
        df['filename'] = df['filename'].astype(str).str.replace('.0', '', regex=False) + ".tif"

        # Ø­Ø°Ù Ø³ØªÙˆÙ† "score" Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        if 'score' in df.columns:
            df = df.drop(columns=['score'])

        merged_data.append(df)

final_df = pd.concat(merged_data, ignore_index=True)
final_df.to_csv(merged_file_path, index=False)

print(f"âœ… ÙØ§ÛŒÙ„ ØªØ¬Ù…ÛŒØ¹ Ø´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {merged_file_path}")

# ---------------------------- 5ï¸âƒ£ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ----------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª CUDA
CUDA_LAUNCH_BLOCKING = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("ğŸš€ Device:", device)

# Ù…Ø³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
root_dir = r"E:\FASTRCNN\FASTRCNN\dataset2\balanced_dataset"
combine_result_dir = os.path.join(root_dir, "\checkpoints_AZ5_TRY1", "COMBINE_RESULT")

# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
merged_file_path = os.path.join(combine_result_dir, "merged_predictions.csv")
test_labels_path = os.path.join(root_dir, "test_labels.csv")

# ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù†ÙÛŒÙˆØ´Ù† Ù…Ø§ØªØ±ÛŒØ³
conf_matrix, true_labels, pred_labels = compute_confusion_matrix(test_labels_path, merged_file_path)

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
precision = precision_score(true_labels, pred_labels, average='macro')
recall = recall_score(true_labels, pred_labels, average='macro')
f1 = f1_score(true_labels, pred_labels, average='macro')

# Ù†Ù…Ø§ÛŒØ´ Ù…Ø§ØªØ±ÛŒØ³ Ú©Ø§Ù†ÙÛŒÙˆØ´Ù†
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix (5x5)")
plt.show()

# Ù†Ù…Ø§ÛŒØ´ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ CSV
metrics_df = pd.DataFrame({
    "Metric": ["Precision", "Recall", "F1 Score"],
    "Value": [precision, recall, f1]
})
metrics_df.to_csv(os.path.join(combine_result_dir, "classification_metrics.csv"), index=False)
print("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯.")